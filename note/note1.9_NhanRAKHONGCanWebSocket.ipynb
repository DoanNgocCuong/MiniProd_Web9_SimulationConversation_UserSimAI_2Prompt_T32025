{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để phân biệt giữa **WebSocket** và **HTTP Streaming**, chúng ta sẽ xem xét cách cả hai hoạt động và khi nào nên sử dụng từng giao thức.\n",
    "\n",
    "### **WebSocket**\n",
    "\n",
    "**WebSocket** là một giao thức cung cấp kết nối **hai chiều** (full-duplex) giữa client và server. Sau khi kết nối được thiết lập, cả hai có thể gửi và nhận dữ liệu bất kỳ lúc nào mà không cần thiết lập lại kết nối mới. Điều này giúp giảm độ trễ và tăng hiệu suất, đặc biệt hữu ích cho các ứng dụng yêu cầu cập nhật thời gian thực như chat trực tuyến, trò chơi trực tuyến, hoặc các ứng dụng tài chính. citeturn0search0\n",
    "\n",
    "**Ví dụ sử dụng WebSocket:**\n",
    "\n",
    "- **Ứng dụng chat trực tuyến:** Khi một người dùng gửi tin nhắn, tin nhắn đó được truyền ngay lập tức đến tất cả người dùng khác trong phòng chat mà không có độ trễ đáng kể.\n",
    "- **Trò chơi trực tuyến:** Thông tin về hành động của người chơi được cập nhật liên tục và ngay lập tức đến tất cả người chơi khác.\n",
    "\n",
    "### **HTTP Streaming**\n",
    "\n",
    "**HTTP Streaming** là một kỹ thuật sử dụng giao thức HTTP để gửi dữ liệu từ server đến client theo từng phần nhỏ, cho phép client nhận dữ liệu liên tục mà không cần đóng kết nối. Mặc dù HTTP truyền thống hoạt động theo mô hình yêu cầu-phản hồi (request-response), HTTP Streaming giữ kết nối mở để gửi dữ liệu liên tục, thường được sử dụng cho các ứng dụng như phát video trực tuyến hoặc cập nhật dữ liệu thời gian thực một chiều. citeturn0search2\n",
    "\n",
    "**Ví dụ sử dụng HTTP Streaming:**\n",
    "\n",
    "- **Phát video trực tuyến:** Server gửi dữ liệu video liên tục đến client, cho phép người dùng xem video mà không cần tải toàn bộ nội dung trước.\n",
    "- **Cập nhật thông tin thời tiết:** Server gửi cập nhật thời tiết mới nhất đến client theo thời gian thực mà không cần client gửi yêu cầu mới.\n",
    "\n",
    "### **So sánh chính giữa WebSocket và HTTP Streaming:**\n",
    "\n",
    "- **Hướng giao tiếp:**\n",
    "  - *WebSocket:* Hai chiều; cả client và server đều có thể gửi dữ liệu bất kỳ lúc nào.\n",
    "  - *HTTP Streaming:* Một chiều; chủ yếu server gửi dữ liệu đến client.\n",
    "\n",
    "- **Thiết lập kết nối:**\n",
    "  - *WebSocket:* Thiết lập một lần và duy trì kết nối mở cho đến khi đóng.\n",
    "  - *HTTP Streaming:* Giữ kết nối HTTP mở để gửi dữ liệu liên tục.\n",
    "\n",
    "- **Độ phức tạp:**\n",
    "  - *WebSocket:* Yêu cầu thiết lập và quản lý kết nối phức tạp hơn.\n",
    "  - *HTTP Streaming:* Dễ triển khai hơn, sử dụng cơ chế HTTP truyền thống.\n",
    "\n",
    "### **Khi nào nên sử dụng cái nào?**\n",
    "\n",
    "- **WebSocket:** Phù hợp cho các ứng dụng yêu cầu giao tiếp hai chiều liên tục và thời gian thực, như chat trực tuyến, trò chơi trực tuyến, hoặc các ứng dụng cần cập nhật liên tục từ cả client và server.\n",
    "\n",
    "- **HTTP Streaming:** Thích hợp cho các ứng dụng cần truyền dữ liệu một chiều liên tục từ server đến client, như phát video trực tuyến, cập nhật tin tức, hoặc các ứng dụng không yêu cầu phản hồi tức thì từ client.\n",
    "\n",
    "Việc lựa chọn giữa WebSocket và HTTP Streaming phụ thuộc vào yêu cầu cụ thể của ứng dụng và mức độ phức tạp mà bạn sẵn lòng chấp nhận trong việc triển khai và quản lý kết nối. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Cập nhật Backend để sử dụng HTTP Streaming thay cho WebSocket\n",
    "\n",
    "Dựa vào yêu cầu của bạn, tôi sẽ cập nhật Backend để sử dụng HTTP Streaming thay cho WebSocket. Dưới đây là các thay đổi cần thiết:\n",
    "\n",
    "## 1. Cập nhật `main.py`\n",
    "\n",
    "````python:WebSimulationConversation/backend/main.py\n",
    "from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Request, Response, HTTPException, Depends\n",
    "from fastapi.responses import StreamingResponse\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import json\n",
    "import asyncio\n",
    "import uuid\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from typing import Dict, List, Optional, Any\n",
    "from pydantic import BaseModel\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "# Cấu hình logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"logs/api.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(\"backend\")\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    logger.warning(\"OPENAI_API_KEY not set. OpenAI features will be disabled.\")\n",
    "    openai_client = None\n",
    "else:\n",
    "    openai_client = AsyncOpenAI(api_key=openai_api_key)\n",
    "\n",
    "# External API configuration\n",
    "EXTERNAL_API_BASE_URL = \"http://103.253.20.13:9404\"\n",
    "INIT_ENDPOINT = f\"{EXTERNAL_API_BASE_URL}/robot-ai-lesson/api/v1/bot/initConversation\"\n",
    "WEBHOOK_ENDPOINT = f\"{EXTERNAL_API_BASE_URL}/robot-ai-lesson/api/v1/bot/webhook\"\n",
    "\n",
    "# Create FastAPI app\n",
    "app = FastAPI(\n",
    "    title=\"WebSimulationConversation API\",\n",
    "    description=\"API for simulating conversations with bots\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# Add CORS middleware\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # Allow all origins\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],  # Allow all methods\n",
    "    allow_headers=[\"*\"],  # Allow all headers\n",
    ")\n",
    "\n",
    "# Define models\n",
    "class ConversationRequest(BaseModel):\n",
    "    bot_id: int\n",
    "    client_id: str\n",
    "    max_turns: Optional[int] = 10\n",
    "    user_prompt: Optional[str] = None\n",
    "\n",
    "class MessageRequest(BaseModel):\n",
    "    content: str\n",
    "    client_id: str\n",
    "\n",
    "class ConversationResponse(BaseModel):\n",
    "    conversation_id: str\n",
    "    status: str = \"created\"\n",
    "\n",
    "# Store active conversations\n",
    "active_conversations: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "# Root endpoint\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    \"\"\"Root endpoint.\"\"\"\n",
    "    return {\n",
    "        \"name\": \"WebSimulationConversation API\",\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"status\": \"running\"\n",
    "    }\n",
    "\n",
    "# Health check endpoint\n",
    "@app.get(\"/health\")\n",
    "async def health():\n",
    "    \"\"\"Health check endpoint.\"\"\"\n",
    "    return {\n",
    "        \"status\": \"healthy\",\n",
    "        \"timestamp\": time.time()\n",
    "    }\n",
    "\n",
    "# API info endpoint\n",
    "@app.get(\"/info\")\n",
    "async def info():\n",
    "    \"\"\"API info endpoint.\"\"\"\n",
    "    return {\n",
    "        \"name\": \"WebSimulationConversation API\",\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"endpoints\": [\n",
    "            \"/\",\n",
    "            \"/health\",\n",
    "            \"/info\",\n",
    "            \"/docs\",\n",
    "            \"/openapi.json\",\n",
    "            \"/api/conversations\",\n",
    "            \"/api/conversations/{conversation_id}/messages\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Initialize conversation\n",
    "@app.post(\"/api/conversations\", response_model=ConversationResponse)\n",
    "async def create_conversation(request: ConversationRequest):\n",
    "    \"\"\"Initialize a new conversation with a bot.\"\"\"\n",
    "    conversation_id = str(uuid.uuid4())\n",
    "    \n",
    "    # Store conversation info\n",
    "    active_conversations[conversation_id] = {\n",
    "        \"bot_id\": request.bot_id,\n",
    "        \"client_id\": request.client_id,\n",
    "        \"max_turns\": request.max_turns,\n",
    "        \"history\": [],\n",
    "        \"created_at\": time.time(),\n",
    "        \"status\": \"created\"\n",
    "    }\n",
    "    \n",
    "    logger.info(f\"Created conversation {conversation_id} for bot {request.bot_id}\")\n",
    "    \n",
    "    return ConversationResponse(conversation_id=conversation_id)\n",
    "\n",
    "# Send message and get streaming response\n",
    "@app.post(\"/api/conversations/{conversation_id}/messages\")\n",
    "async def send_message(conversation_id: str, request: MessageRequest):\n",
    "    \"\"\"Send a message to the bot and get a streaming response.\"\"\"\n",
    "    # Check if conversation exists\n",
    "    if conversation_id not in active_conversations:\n",
    "        raise HTTPException(status_code=404, detail=\"Conversation not found\")\n",
    "    \n",
    "    # Get conversation info\n",
    "    conversation = active_conversations[conversation_id]\n",
    "    \n",
    "    # Check if client ID matches\n",
    "    if conversation[\"client_id\"] != request.client_id:\n",
    "        raise HTTPException(status_code=403, detail=\"Client ID mismatch\")\n",
    "    \n",
    "    # Add user message to history\n",
    "    conversation[\"history\"].append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": request.content,\n",
    "        \"timestamp\": time.time()\n",
    "    })\n",
    "    \n",
    "    # Create streaming response\n",
    "    return StreamingResponse(\n",
    "        process_message(conversation_id, request.content),\n",
    "        media_type=\"text/event-stream\"\n",
    "    )\n",
    "\n",
    "async def process_message(conversation_id: str, message: str):\n",
    "    \"\"\"Process a message and yield streaming responses.\"\"\"\n",
    "    conversation = active_conversations[conversation_id]\n",
    "    bot_id = conversation[\"bot_id\"]\n",
    "    \n",
    "    # Initialize conversation with external API if needed\n",
    "    if len(conversation[\"history\"]) == 1:  # First message\n",
    "        yield format_sse_event({\"status\": \"initializing\", \"message\": f\"Đang khởi tạo cuộc hội thoại với Bot ID: {bot_id}...\"})\n",
    "        \n",
    "        try:\n",
    "            # Initialize conversation with external API\n",
    "            init_payload = {\n",
    "                \"bot_id\": bot_id,\n",
    "                \"conversation_id\": conversation_id,\n",
    "                \"input_slots\": {}\n",
    "            }\n",
    "            \n",
    "            init_response = requests.post(\n",
    "                INIT_ENDPOINT,\n",
    "                headers={'Content-Type': 'application/json'},\n",
    "                json=init_payload,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if init_response.status_code != 200:\n",
    "                yield format_sse_event({\"error\": f\"Failed to initialize conversation: HTTP {init_response.status_code}\"})\n",
    "                return\n",
    "            \n",
    "            init_data = init_response.json()\n",
    "            if init_data.get(\"status\") != 0 or init_data.get(\"msg\") != \"Success\":\n",
    "                yield format_sse_event({\"error\": f\"API returned error: {init_data}\"})\n",
    "                return\n",
    "            \n",
    "            yield format_sse_event({\"status\": \"initialized\", \"message\": \"Cuộc hội thoại đã được khởi tạo thành công\"})\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error initializing conversation: {str(e)}\")\n",
    "            yield format_sse_event({\"error\": f\"Error initializing conversation: {str(e)}\"})\n",
    "            return\n",
    "    \n",
    "    # Send message to external API\n",
    "    yield format_sse_event({\"status\": \"sending\", \"message\": \"Đang gửi tin nhắn...\"})\n",
    "    \n",
    "    try:\n",
    "        # Send message to external API\n",
    "        webhook_payload = {\n",
    "            \"conversation_id\": conversation_id,\n",
    "            \"message\": message\n",
    "        }\n",
    "        \n",
    "        webhook_response = requests.post(\n",
    "            WEBHOOK_ENDPOINT,\n",
    "            headers={'Content-Type': 'application/json'},\n",
    "            json=webhook_payload,\n",
    "            timeout=30\n",
    "        )\n",
    "        \n",
    "        if webhook_response.status_code != 200:\n",
    "            yield format_sse_event({\"error\": f\"Failed to send message: HTTP {webhook_response.status_code}\"})\n",
    "            return\n",
    "        \n",
    "        webhook_data = webhook_response.json()\n",
    "        \n",
    "        # Check if response contains a message\n",
    "        bot_response = webhook_data.get(\"data\", {}).get(\"message\", \"\")\n",
    "        if not bot_response:\n",
    "            yield format_sse_event({\"error\": \"No response from bot\"})\n",
    "            return\n",
    "        \n",
    "        # Add bot response to history\n",
    "        conversation[\"history\"].append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": bot_response,\n",
    "            \"timestamp\": time.time()\n",
    "        })\n",
    "        \n",
    "        # Stream the response in chunks\n",
    "        chunk_size = 10  # Characters per chunk\n",
    "        for i in range(0, len(bot_response), chunk_size):\n",
    "            chunk = bot_response[i:i+chunk_size]\n",
    "            yield format_sse_event({\"content\": chunk})\n",
    "            await asyncio.sleep(0.05)  # Small delay between chunks\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error sending message: {str(e)}\")\n",
    "        yield format_sse_event({\"error\": f\"Error sending message: {str(e)}\"})\n",
    "        return\n",
    "\n",
    "def format_sse_event(data: Dict[str, Any]) -> str:\n",
    "    \"\"\"Format data as a Server-Sent Event.\"\"\"\n",
    "    json_data = json.dumps(data)\n",
    "    return f\"data: {json_data}\\n\\n\"\n",
    "\n",
    "# Get conversation history\n",
    "@app.get(\"/api/conversations/{conversation_id}\")\n",
    "async def get_conversation(conversation_id: str, client_id: str):\n",
    "    \"\"\"Get conversation history.\"\"\"\n",
    "    # Check if conversation exists\n",
    "    if conversation_id not in active_conversations:\n",
    "        raise HTTPException(status_code=404, detail=\"Conversation not found\")\n",
    "    \n",
    "    # Get conversation info\n",
    "    conversation = active_conversations[conversation_id]\n",
    "    \n",
    "    # Check if client ID matches\n",
    "    if conversation[\"client_id\"] != client_id:\n",
    "        raise HTTPException(status_code=403, detail=\"Client ID mismatch\")\n",
    "    \n",
    "    return {\n",
    "        \"conversation_id\": conversation_id,\n",
    "        \"bot_id\": conversation[\"bot_id\"],\n",
    "        \"history\": conversation[\"history\"],\n",
    "        \"created_at\": conversation[\"created_at\"]\n",
    "    }\n",
    "\n",
    "# Generate user response using OpenAI\n",
    "@app.post(\"/api/generate-user-response\")\n",
    "async def generate_user_response(request: dict):\n",
    "    \"\"\"Generate a user response using OpenAI.\"\"\"\n",
    "    if not openai_client:\n",
    "        raise HTTPException(status_code=503, detail=\"OpenAI client not initialized\")\n",
    "    \n",
    "    try:\n",
    "        # Extract conversation history\n",
    "        history = request.get(\"history\", [])\n",
    "        \n",
    "        # Prepare the prompt for OpenAI\n",
    "        system_prompt = \"\"\"\n",
    "        You are a helpful assistant that generates the next user message in a conversation.\n",
    "        The user is learning English from a bot. Generate a natural, brief response that continues the conversation.\n",
    "        Your response should be in Vietnamese and should be a single message without any explanation or additional text.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Format conversation history for the prompt\n",
    "        formatted_history = []\n",
    "        for msg in history:\n",
    "            role = \"user\" if msg[\"role\"] == \"user\" else \"assistant\"\n",
    "            formatted_history.append({\"role\": role, \"content\": msg[\"content\"]})\n",
    "        \n",
    "        # Add system message at the beginning\n",
    "        messages = [{\"role\": \"system\", \"content\": system_prompt}] + formatted_history\n",
    "        \n",
    "        # Generate response\n",
    "        response = await openai_client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            max_tokens=100,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        user_message = response.choices[0].message.content.strip()\n",
    "        \n",
    "        return {\n",
    "            \"content\": user_message\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating user response: {str(e)}\")\n",
    "        raise HTTPException(status_code=500, detail=f\"Error generating user response: {str(e)}\")\n",
    "\n",
    "# Run simulation\n",
    "@app.post(\"/api/simulate\")\n",
    "async def simulate_conversation(request: dict):\n",
    "    \"\"\"Run a full conversation simulation.\"\"\"\n",
    "    if not openai_client:\n",
    "        raise HTTPException(status_code=503, detail=\"OpenAI client not initialized\")\n",
    "    \n",
    "    try:\n",
    "        # Extract parameters\n",
    "        bot_id = request.get(\"bot_id\", 16)\n",
    "        initial_message = request.get(\"initial_message\", \"sẵn sàng\")\n",
    "        max_turns = request.get(\"max_turns\", 3)\n",
    "        \n",
    "        # Create a client ID\n",
    "        client_id = f\"simulation-{uuid.uuid4()}\"\n",
    "        \n",
    "        # Initialize conversation\n",
    "        conversation_request = ConversationRequest(\n",
    "            bot_id=bot_id,\n",
    "            client_id=client_id,\n",
    "            max_turns=max_turns\n",
    "        )\n",
    "        \n",
    "        conversation_response = await create_conversation(conversation_request)\n",
    "        conversation_id = conversation_response.conversation_id\n",
    "        \n",
    "        # Send initial message\n",
    "        message_request = MessageRequest(\n",
    "            content=initial_message,\n",
    "            client_id=client_id\n",
    "        )\n",
    "        \n",
    "        # Process the conversation manually instead of using StreamingResponse\n",
    "        conversation = active_conversations[conversation_id]\n",
    "        \n",
    "        # Add initial message to history\n",
    "        conversation[\"history\"].append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": initial_message,\n",
    "            \"timestamp\": time.time()\n",
    "        })\n",
    "        \n",
    "        # Initialize conversation with external API\n",
    "        init_payload = {\n",
    "            \"bot_id\": bot_id,\n",
    "            \"conversation_id\": conversation_id,\n",
    "            \"input_slots\": {}\n",
    "        }\n",
    "        \n",
    "        init_response = requests.post(\n",
    "            INIT_ENDPOINT,\n",
    "            headers={'Content-Type': 'application/json'},\n",
    "            json=init_payload,\n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        if init_response.status_code != 200:\n",
    "            raise HTTPException(status_code=500, detail=f\"Failed to initialize conversation: HTTP {init_response.status_code}\")\n",
    "        \n",
    "        init_data = init_response.json()\n",
    "        if init_data.get(\"status\") != 0 or init_data.get(\"msg\") != \"Success\":\n",
    "            raise HTTPException(status_code=500, detail=f\"API returned error: {init_data}\")\n",
    "        \n",
    "        # Run turns\n",
    "        for turn in range(max_turns):\n",
    "            # Get the last user message\n",
    "            last_user_message = next((msg[\"content\"] for msg in reversed(conversation[\"history\"]) if msg[\"role\"] == \"user\"), None)\n",
    "            \n",
    "            if not last_user_message:\n",
    "                break\n",
    "            \n",
    "            # Send message to external API\n",
    "            webhook_payload = {\n",
    "                \"conversation_id\": conversation_id,\n",
    "                \"message\": last_user_message\n",
    "            }\n",
    "            \n",
    "            webhook_response = requests.post(\n",
    "                WEBHOOK_ENDPOINT,\n",
    "                headers={'Content-Type': 'application/json'},\n",
    "                json=webhook_payload,\n",
    "                timeout=30\n",
    "            )\n",
    "            \n",
    "            if webhook_response.status_code != 200:\n",
    "                raise HTTPException(status_code=500, detail=f\"Failed to send message: HTTP {webhook_response.status_code}\")\n",
    "            \n",
    "            webhook_data = webhook_response.json()\n",
    "            \n",
    "            # Check if response contains a message\n",
    "            bot_response = webhook_data.get(\"data\", {}).get(\"message\", \"\")\n",
    "            if not bot_response:\n",
    "                raise HTTPException(status_code=500, detail=\"No response from bot\")\n",
    "            \n",
    "            # Add bot response to history\n",
    "            conversation[\"history\"].append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": bot_response,\n",
    "                \"timestamp\": time.time()\n",
    "            })\n",
    "            \n",
    "            # If this is the last turn, break\n",
    "            if turn == max_turns - 1:\n",
    "                break\n",
    "            \n",
    "            # Generate user response\n",
    "            system_prompt = \"\"\"\n",
    "            You are a helpful assistant that generates the next user message in a conversation.\n",
    "            The user is learning English from a bot. Generate a natural, brief response that continues the conversation.\n",
    "            Your response should be in Vietnamese and should be a single message without any explanation or additional text.\n",
    "            \"\"\"\n",
    "            \n",
    "            # Format conversation history for the prompt\n",
    "            formatted_history = []\n",
    "            for msg in conversation[\"history\"]:\n",
    "                role = \"user\" if msg[\"role\"] == \"user\" else \"assistant\"\n",
    "                formatted_history.append({\"role\": role, \"content\": msg[\"content\"]})\n",
    "            \n",
    "            # Add system message at the beginning\n",
    "            messages = [{\"role\": \"system\", \"content\": system_prompt}] + formatted_history\n",
    "            \n",
    "            # Generate response\n",
    "            response = await openai_client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=messages,\n",
    "                max_tokens=100,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            \n",
    "            user_message = response.choices[0].message.content.strip()\n",
    "            \n",
    "            # Add user message to history\n",
    "            conversation[\"history\"].append({\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_message,\n",
    "                \"timestamp\": time.time()\n",
    "            })\n",
    "        \n",
    "        # Return the conversation history\n",
    "        return {\n",
    "            \"conversation_id\": conversation_id,\n",
    "            \"bot_id\": conversation[\"bot_id\"],\n",
    "            \"history\": conversation[\"history\"],\n",
    "            \"created_at\": conversation[\"created_at\"]\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error simulating conversation: {str(e)}\")\n",
    "        raise HTTPException(status_code=500, detail=f\"Error simulating conversation: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=25050)\n",
    "````\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 2. Cập nhật `requirements.txt`\n",
    "\n",
    "````\n",
    "fastapi==0.104.1\n",
    "uvicorn==0.23.2\n",
    "websockets==11.0.3\n",
    "python-dotenv==1.0.0\n",
    "requests==2.31.0\n",
    "openai==1.3.5\n",
    "pydantic==2.4.2\n",
    "````\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 3. Cập nhật `Dockerfile`\n",
    "\n",
    "````Dockerfile:WebSimulationConversation/backend/Dockerfile\n",
    "FROM python:3.9-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "COPY . .\n",
    "\n",
    "# Create logs directory\n",
    "RUN mkdir -p logs\n",
    "\n",
    "# Expose port\n",
    "EXPOSE 25050\n",
    "\n",
    "# Run the application\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"25050\"]\n",
    "````\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Giải thích các thay đổi chính\n",
    "\n",
    "1. **Chuyển từ WebSocket sang HTTP Streaming**:\n",
    "   - Thay thế WebSocket endpoints bằng HTTP endpoints\n",
    "   - Sử dụng `StreamingResponse` của FastAPI để tạo HTTP Streaming\n",
    "   - Sử dụng Server-Sent Events (SSE) để gửi dữ liệu từ server đến client\n",
    "\n",
    "2. **Thêm các endpoint mới**:\n",
    "   - `/api/conversations`: Khởi tạo cuộc hội thoại\n",
    "   - `/api/conversations/{conversation_id}/messages`: Gửi tin nhắn và nhận phản hồi dạng streaming\n",
    "   - `/api/conversations/{conversation_id}`: Lấy lịch sử hội thoại\n",
    "   - `/api/generate-user-response`: Tạo tin nhắn người dùng bằng OpenAI\n",
    "   - `/api/simulate`: Chạy một cuộc hội thoại đầy đủ\n",
    "\n",
    "3. **Thêm các endpoint thông tin**:\n",
    "   - `/`: Endpoint gốc\n",
    "   - `/health`: Kiểm tra trạng thái\n",
    "   - `/info`: Thông tin API\n",
    "\n",
    "4. **Cải thiện xử lý lỗi**:\n",
    "   - Sử dụng `HTTPException` để trả về lỗi với mã trạng thái HTTP phù hợp\n",
    "   - Ghi log chi tiết khi có lỗi xảy ra\n",
    "\n",
    "5. **Cải thiện cấu trúc dữ liệu**:\n",
    "   - Sử dụng Pydantic models để xác thực dữ liệu đầu vào\n",
    "   - Lưu trữ lịch sử hội thoại trong bộ nhớ\n",
    "\n",
    "## Cách sử dụng\n",
    "\n",
    "1. **Khởi tạo cuộc hội thoại**:\n",
    "   ```\n",
    "   POST /api/conversations\n",
    "   {\n",
    "     \"bot_id\": 16,\n",
    "     \"client_id\": \"your-client-id\",\n",
    "     \"max_turns\": 10\n",
    "   }\n",
    "   ```\n",
    "\n",
    "2. **Gửi tin nhắn và nhận phản hồi dạng streaming**:\n",
    "   ```\n",
    "   POST /api/conversations/{conversation_id}/messages\n",
    "   {\n",
    "     \"content\": \"sẵn sàng\",\n",
    "     \"client_id\": \"your-client-id\"\n",
    "   }\n",
    "   ```\n",
    "\n",
    "3. **Lấy lịch sử hội thoại**:\n",
    "   ```\n",
    "   GET /api/conversations/{conversation_id}?client_id=your-client-id\n",
    "   ```\n",
    "\n",
    "4. **Chạy một cuộc hội thoại đầy đủ**:\n",
    "   ```\n",
    "   POST /api/simulate\n",
    "   {\n",
    "     \"bot_id\": 16,\n",
    "     \"initial_message\": \"sẵn sàng\",\n",
    "     \"max_turns\": 3\n",
    "   }\n",
    "   ```\n",
    "\n",
    "## Kết luận\n",
    "\n",
    "Việc chuyển từ WebSocket sang HTTP Streaming giúp:\n",
    "1. Đơn giản hóa việc triển khai và sử dụng API\n",
    "2. Tương thích tốt hơn với các client không hỗ trợ WebSocket\n",
    "3. Dễ dàng tích hợp với các công cụ và framework hiện đại\n",
    "4. Vẫn duy trì khả năng streaming dữ liệu từ server đến client\n",
    "\n",
    "Backend mới này cung cấp đầy đủ các tính năng của phiên bản WebSocket trước đó, đồng thời bổ sung thêm nhiều tính năng mới và cải thiện trải nghiệm người dùng.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Đoạn code này. \n",
    "Muốn đóng nó thành 1 API endpoint \n",
    "\n",
    "Input gồm: \n",
    "curl --location 'http://103.253.20.13:25050/simulate' \\\n",
    "--header 'Content-Type: application/json' \\\n",
    "--data '{\n",
    "    \"bot_id\": 16,\n",
    "    \"user_prompt\": \"sẵn sàng\",\n",
    "    \"max_turns\": 1,\n",
    "    \"history\": \"[{\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"sẵn sàng\\\"}]\"\n",
    "}'\n",
    "\n",
    "\n",
    "output trả ra text: \n",
    "User: sẵn sàng \n",
    "Bot: ...\n",
    "User: ...\n",
    "Bot: ...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chẳng hạn: \n",
    "Input của em là 2 Prompt chat với nhau (bên trong là code xử lý cho 2 prompt nói chuyện, tầm 5 phút output nó mới trả ra). \n",
    "===\n",
    "Xài FastAPI tầm 5 min output mới trả ra. \n",
    "trong quá trình call API, làm sao em tracking được output của nó? "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
